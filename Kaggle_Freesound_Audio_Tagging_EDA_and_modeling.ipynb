{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Kaggle - Freesound Audio Tagging - EDA and modeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdebrain/kaggle-freesound-audio-tagging-2019/blob/main/Kaggle_Freesound_Audio_Tagging_EDA_and_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "6RxYCQQW2duQ"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import h5py\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
        "from sklearn.metrics import label_ranking_average_precision_score as lrap\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, MaxPool2D, Conv2D, AvgPool2D, ReLU, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda, LeakyReLU\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq_teBrG2duV"
      },
      "source": [
        "# 1. Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6oYaQYlN2duW"
      },
      "source": [
        "def load_train_data_df(mode='curated'):\n",
        "    # Load training data filenames and labels (raw -> multilabels are represented as a string with comma separated values)\n",
        "    data_folder = '/kaggle/input/freesound-audio-tagging-2019' \n",
        "    csv_path = f'{data_folder}/train_{mode}.csv'\n",
        "    raw_df = pd.read_csv(csv_path, index_col='fname')\n",
        "        \n",
        "    # Extract list of expected labels\n",
        "    sub = pd.read_csv('/kaggle/input/freesound-audio-tagging-2019/sample_submission.csv', index_col='fname')\n",
        "    labels_list = sub.columns.values \n",
        "\n",
        "    # Encode multi-labels in a binary vector\n",
        "    splitted_labels = [ labels.split(',') for labels in raw_df['labels'].values ]\n",
        "    encoder = MultiLabelBinarizer()\n",
        "    encoded_labels = encoder.fit_transform(splitted_labels)\n",
        "\n",
        "    # Create a new pandas Dataframe to represent training labels as binary vectors\n",
        "    labels_df = pd.DataFrame(data=encoded_labels, index=list(raw_df.index), columns=labels_list)\n",
        "    \n",
        "    return labels_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SI4vu1hj2duY"
      },
      "source": [
        "# Load data filenames and labels\n",
        "train_curated_labels = load_train_data_df(mode='curated')\n",
        "train_noisy_labels = load_train_data_df(mode='noisy')\n",
        "test_labels = pd.read_csv('/kaggle/input/freesound-audio-tagging-2019/sample_submission.csv', index_col='fname')\n",
        "\n",
        "# Main info about the training/testing sets\n",
        "print(f'{train_curated_labels.shape[1]} possible classes.')\n",
        "print(f'{train_curated_labels.shape[0]} curated training samples.')\n",
        "print(f'{train_noisy_labels.shape[0]} noisy training samples.')\n",
        "print(f'{test_labels.shape[0]} test samples.')\n",
        "\n",
        "train_curated_labels.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_iQDTlt-2duZ"
      },
      "source": [
        "# OPTIONAL - Reduced train dataset (10 random classes ~750 curated samples and ~3000 noisy labels)\n",
        "use_reduced_data = True\n",
        "n_classes = 80\n",
        "\n",
        "if use_reduced_data:\n",
        "    n_classes = 10\n",
        "    labels_list = np.random.choice(train_curated_labels.columns, 10, replace=False)\n",
        "    samples_to_keep = train_curated_labels.loc[:, labels_list].sum(axis=1) > 0\n",
        "    train_curated_labels = train_curated_labels.loc[samples_to_keep, labels_list]\n",
        "    print(f'Using reduced curated dataset {train_curated_labels.shape}.')\n",
        "    print(train_curated_labels.sum())\n",
        "    \n",
        "    samples_to_keep = train_noisy_labels.loc[:, labels_list].sum(axis=1) > 0\n",
        "    train_noisy_labels = train_noisy_labels.loc[samples_to_keep, labels_list]\n",
        "    print(f'Using reduced noisy dataset {train_noisy_labels.shape}.')\n",
        "    print(train_noisy_labels.sum())\n",
        "    \n",
        "train_curated_h5 = '/kaggle/input/fat2019wav/train_curated_wav.h5'\n",
        "train_curated_ids = np.array([ 't' + file.split('.')[0] for file in train_curated_labels.index.values ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Usp1exz2dua"
      },
      "source": [
        "# 2. Data exploration (fat2019wav dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BB1ViQBF2dua"
      },
      "source": [
        "def load_h5(sample_ids, h5_filename):\n",
        "    if not isinstance(sample_ids, np.ndarray):\n",
        "        sample_ids = np.array([sample_ids])\n",
        "    with h5py.File(h5_filename, mode='r') as dataset:\n",
        "        samples = [ convert_to_float(dataset[f][()]) for f in sample_ids ]\n",
        "    return samples\n",
        "\n",
        "def load_random_wav(sample_ids, h5_filename):\n",
        "    random_id = np.random.choice(train_curated_ids, 1)[0]\n",
        "    sample = load_h5(random_id, h5_filename)[0]\n",
        "    return random_id, sample\n",
        "\n",
        "def get_label(sample_id, labels_df, decode_label=False):\n",
        "    label = labels_df.loc[sample_id[1:] + '.wav']\n",
        "    if decode_label:\n",
        "        label = list(label[label>0].index)\n",
        "    return label \n",
        "\n",
        "def listen_sample(sample, sr=44100):\n",
        "    return IPython.display.display(ipd.Audio(data=sample, rate=sr))\n",
        "\n",
        "def convert_to_float(sample):\n",
        "    return np.array(sample) / 255.\n",
        "\n",
        "def show_signal(sample, mode='temporal', ax=None, sr=44100):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "        \n",
        "    if mode == 'temporal':\n",
        "        librosa.display.waveplot(sample, sr=sr, ax=ax)\n",
        "        ax.set_title('Temporal')\n",
        "        print(f'Temporal: {sample.shape}')\n",
        "    elif mode == 'stft':\n",
        "        stft = librosa.stft(sample)\n",
        "        stft = np.abs(stft)\n",
        "        stft = librosa.amplitude_to_db(abs(stft), ref=np.max)\n",
        "        librosa.display.specshow(stft, x_axis='time', y_axis='log', sr=sr, ax=ax)\n",
        "        ax.set_title('STFT')\n",
        "        print(f'STFT: {stft.shape}')\n",
        "    elif mode == 'mfcc':\n",
        "        mfccs = librosa.feature.mfcc(sample, sr=sr, n_mfcc=20)\n",
        "        librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=ax)\n",
        "        ax.set_title('MFCC')\n",
        "        print(f'MFCC: {mfccs.shape}')\n",
        "    elif mode == 'logmel':\n",
        "        mel = librosa.feature.melspectrogram(y=sample, sr=sr, n_fft=1024, hop_length=512, n_mels=128, fmin=20, fmax=sr//2)\n",
        "        mel = librosa.core.power_to_db(mel, ref=np.max)\n",
        "        librosa.display.specshow(mel, sr=sr, x_axis='time', y_axis='mel', hop_length=512, fmin=20, fmax=sr//2, ax=ax)\n",
        "        ax.set_title('Log-Mel')\n",
        "        print(f'Log-Mel: {mel.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CDzRMmlP2dub"
      },
      "source": [
        "# Load random .wav sample\n",
        "sr = 44100\n",
        "random_id, sample = load_random_wav(train_curated_ids, train_curated_h5)\n",
        "labels = get_label(random_id, train_curated_labels, decode_label=True)\n",
        "listen_sample(sample)\n",
        "\n",
        "print(f'Length: {len(sample)/sr:.2f}s')\n",
        "print(f'Labels: {labels}')\n",
        "\n",
        "fig, ax = plt.subplots(4, 1, figsize=(16,10))\n",
        "show_signal(sample, mode='temporal', ax=ax[0])\n",
        "show_signal(sample, mode='stft', ax=ax[1])\n",
        "show_signal(sample, mode='mfcc', ax=ax[2])\n",
        "show_signal(sample, mode='logmel', ax=ax[3])\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJk0sr7K2dub"
      },
      "source": [
        "**STFT (Short Term Fourier Transform):** Computes the amplitude of the frequencies for different bands  over time. <br>\n",
        "**MFCC (Mel Frequency Cepstral Coefficients):** Describe the instantaneous spectral envelope shape of the speech signal. [[source](https://wiki.aalto.fi/display/ITSP/Deltas+and+Delta-deltas)] <br>\n",
        "**Mel spectrogram:** Similar to STFT but represented in the Mel scale (non-linear transformation of the frequency scale), that is closer to how humans perceive sounds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CgZFTpMP2duc"
      },
      "source": [
        "# Histogram of labels distribution\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "train_curated_labels.sum(axis=0).sort_values(ascending=True).plot(kind='barh', x='Count', y=train_curated_labels.columns, ax=ax)\n",
        "ax.set_xlabel('Count')\n",
        "ax.set_title('Distribution of training labels');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohSgVlJ62duc"
      },
      "source": [
        "**Remark:** Most labels are fairly equally distributed, but we might want to oversample the last 14 labels in order to have equally represented labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rDjQSluq2due"
      },
      "source": [
        "# Extract duration of each sample in the curated training set\n",
        "curated_len_df = pd.DataFrame(columns=['fname', 'length'])\n",
        "curated_len_df.set_index(['fname'], inplace=True)\n",
        "\n",
        "for file in train_curated_ids:\n",
        "    sample = load_h5(file, train_curated_h5)[0]\n",
        "    \n",
        "    fname = file.split('/')[-1]\n",
        "    curated_len_df.loc[fname] = len(sample) / sr\n",
        "\n",
        "curated_len_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LQjY6fyO2due"
      },
      "source": [
        "# Histogram of signal length distribution\n",
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "curated_len_df['length'].sort_values(ascending=False).plot(kind='hist', bins=100, ax=ax)\n",
        "ax.set_xlim([0,31])\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_xlabel('Duration (s)')\n",
        "ax.set_title('Distribution of signal durations');\n",
        "\n",
        "print(f'Smallest duration: {curated_len_df[\"length\"].min():.2f}s')\n",
        "print(f'Largest duration: {curated_len_df[\"length\"].max():.2f}s')\n",
        "print(f'Mean duration: {curated_len_df[\"length\"].mean():.2f}s')\n",
        "print(f'Median duration: {curated_len_df[\"length\"].median():.2f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vc-Wncd2due"
      },
      "source": [
        "**Remark:** >50% of all samples are less than 5s long. We should think about a cropping strategy in order to have fixed-length samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNsgOtFW2duf"
      },
      "source": [
        "# 3. Feature extraction\n",
        "\n",
        "We can extract log melspectrogram features (n_mels=128) using Librosa and the following parameters:\n",
        "- sr = 44100\n",
        "- nmels = 128 \n",
        "- nfft = 1024\n",
        "- hop_length = 512\n",
        "- fmin = 20\n",
        "- fmax = sr//2\n",
        "\n",
        "See [Kaggle notebook](https://www.kaggle.com/obione26/freesound-audio-tagging-feature-extraction) ([Colab version](https://colab.research.google.com/drive/1uTEdXfazhonVHxP4vmuYAgG2BexzHfcu?usp=sharing))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVoj6ep72duf"
      },
      "source": [
        "# 4. Data modeling\n",
        "\n",
        "\n",
        "Model architecture inspired from [this notebook](https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data) and this [github](https://github.com/sainathadapa/kaggle-freesound-audio-tagging/blob/master/approaches_all.md). <br>\n",
        "Augmentation methods inspired from [this notebook](https://www.kaggle.com/osciiart/resnet34-multi1024).\n",
        "\n",
        "**Metrics:**\n",
        "- **LWLRAP (Label-Weighted Label-Ranking Average Precision):** Evaluates the ability of a model (given the predicted ranked list of labels probabilities) to give higher probabilities to the relevant labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OW_de2vW2duf"
      },
      "source": [
        "# Helper functions of this section\n",
        "def extract_mel(sample, n_mels=128, sr=44100, hop=512, log=False):\n",
        "    \"\"\" Return melspectrogram of shape (n_mels, len(sample)/hop + 1). \"\"\"\n",
        "    mel = librosa.feature.melspectrogram(sample, sr=sr, n_fft=1024, hop_length=hop, n_mels=n_mels, fmin=20, fmax=sr//2)\n",
        "    if log:\n",
        "        mel = librosa.core.power_to_db(mel, ref=1.0, amin=1e-10, top_db=None)\n",
        "    return mel.astype(np.float32)\n",
        "\n",
        "def random_chunk(x, chunk_size=44100, hop_len=512):\n",
        "    \"\"\" Extract fixed-size chunk from signal. If signal shorter than chunk size -> repeat pattern. Else -> random cropping.\n",
        "    Parameters:\n",
        "    - chunk_size (int, >0): Number of frames in a chunk (corresponds to chunk_size*hop_len/sr seconds).\n",
        "    - hop_len (int, >0): Number of temporal frames represented in one mel frame.\n",
        "    \"\"\"\n",
        "    n_frames = x.shape[-1]\n",
        "    \n",
        "    if n_frames <= chunk_size:\n",
        "        x = np.tile(x, chunk_size//n_frames + 1)\n",
        "        x = x[..., :chunk_size]\n",
        "    else:\n",
        "        roi_start = np.random.randint(0, n_frames - chunk_size)\n",
        "        x = x[..., roi_start:roi_start + chunk_size]\n",
        "    return x\n",
        "\n",
        "def random_ampli(x, min_gain=0.5, max_gain=2):\n",
        "    rate = (max_gain - min_gain) * np.random.random() + min_gain\n",
        "    return rate * x\n",
        "\n",
        "def mixup(x, label, source_ids, source_h5, source_labels, chunk_size, hop_len, alpha=1.):\n",
        "    \"\"\" Return a weighted combination of audio samples and labels. \"\"\"\n",
        "    if x.shape[-1] != chunk_size:\n",
        "        x = random_chunk(x, chunk_size, hop_len)\n",
        "    \n",
        "    # Load second signal and associated label\n",
        "    random_id2, sample2 = load_random_wav(source_ids, source_h5)\n",
        "    sample2 = random_chunk(sample2, chunk_size, hop_len)\n",
        "    label2 = get_label(random_id2, source_labels)\n",
        "    \n",
        "    # Combine input signals and labels\n",
        "#     rate = np.random.beta(alpha, alpha)\n",
        "    rate = np.random.random()\n",
        "    x = rate * x + (1-rate) * sample2\n",
        "    label = rate * label + (1-rate) * label2\n",
        "    \n",
        "    return x, label\n",
        "\n",
        "def normalize(X):\n",
        "    mean = X.mean(axis=0, keepdims=True)\n",
        "    std = X.std(axis=0, keepdims=True)\n",
        "    X = (X - mean) / (std + 1e-7)\n",
        "    return X\n",
        "\n",
        "class DataLoader(Sequence):\n",
        "    def __init__(self, h5_file, sample_ids, labels_df, batch_size, chunk_size=44100, n_mels=128, hop=512, sr=44100, compute_deltas=False, shuffle=True):\n",
        "        self.h5_file = h5_file\n",
        "        self.sample_ids = np.array(sample_ids)\n",
        "        self.labels_df = labels_df\n",
        "        self.batch_size = batch_size\n",
        "        self.chunk_size = chunk_size\n",
        "        self.n_mels = n_mels\n",
        "        self.hop = hop\n",
        "        self.sr = sr\n",
        "        self.compute_deltas = compute_deltas\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "        # FIXME: Create mel dataset\n",
        "        self.X = load_h5(self.sample_ids, self.h5_file)\n",
        "        self.X = [ extract_mel(x, n_mels, sr, hop, log=True) for x in self.X]\n",
        "        self.y = np.array([ get_label(id, self.labels_df) for id in self.sample_ids ])\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Corresponds to the number of steps in one epoch. \"\"\"\n",
        "        return int(np.ceil(len(self.sample_ids) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n",
        "        batch_X, batch_y = self.generate_Xy(indexes)\n",
        "        \n",
        "        if self.compute_deltas:\n",
        "            pass\n",
        "                    \n",
        "        batch_X = normalize(batch_X)\n",
        "        batch_X = np.expand_dims(batch_X, axis=-1)\n",
        "        \n",
        "        return batch_X, batch_y\n",
        "\n",
        "    def generate_Xy(self, indexes):\n",
        "        # Fixed-length size \n",
        "        X = [ random_chunk(self.X[i], self.chunk_size, self.hop) for i in indexes ]\n",
        "        y = self.y[indexes]\n",
        "#             x = random_ampli(x)\n",
        "#             x, label = mixup(x, label, self.mel_paths, self.labels_df, self.chunk_size, self.hop, alpha=1.)\n",
        "        return np.array(X).astype(np.float32), np.array(y).astype(np.float32)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        \"\"\" Shuffle the data after each epoch to avoid oscillation patterns in the loss. \"\"\"\n",
        "        self.indexes = np.arange(0, len(self.sample_ids))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "class CNN9:\n",
        "    def __init__(self, n_feats=128, chunk_size=44100, hop=512, n_classes=80):\n",
        "        self.n_feats = n_feats\n",
        "        self.n_frames = int(chunk_size / hop + 1)\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "    def add_conv_block(self, n_filts, k_size):\n",
        "        self.model.add(Conv2D(n_filts, k_size, padding='same'))\n",
        "        self.model.add(LeakyReLU(alpha=0.01))\n",
        "        self.model.add(BatchNormalization(momentum=0.1))\n",
        "        self.model.add(ReLU())\n",
        "        \n",
        "        self.model.add(Conv2D(n_filts, k_size, padding='same'))\n",
        "        self.model.add(LeakyReLU(alpha=0.01))\n",
        "        self.model.add(BatchNormalization(momentum=0.1))\n",
        "        self.model.add(ReLU())\n",
        "        \n",
        "    def create_model(self):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Input(shape=(self.n_feats, self.n_frames, 1)))\n",
        "\n",
        "        self.add_conv_block(n_filts=64, k_size=(3,3))\n",
        "        self.model.add(AvgPool2D(pool_size=(2,2)))\n",
        "\n",
        "        self.add_conv_block(n_filts=128, k_size=(3,3))\n",
        "        self.model.add(AvgPool2D(pool_size=(2,2)))\n",
        "\n",
        "        self.add_conv_block(n_filts=256, k_size=(3,3))\n",
        "        self.model.add(AvgPool2D(pool_size=(2,2)))\n",
        "\n",
        "        self.add_conv_block(n_filts=512, k_size=(3,3))\n",
        "        self.model.add(AvgPool2D(pool_size=(1,1)))\n",
        "\n",
        "        self.model.add(Lambda(lambda x: K.max(K.mean(x, axis=3), axis=2)))\n",
        "        self.model.add(Dense(512, activation='relu'))\n",
        "        self.model.add(Dense(self.n_classes, activation='softmax'))\n",
        "\n",
        "        return self.model\n",
        "\n",
        "def create_shallow_cnn(n_feats=128, chunk_size=512, n_classes=80):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_feats, chunk_size, 1)))\n",
        "\n",
        "    model.add(Conv2D(48, 11, strides=(2,3),kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(3, strides=(1,2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(128, 5, strides=(2,3), kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(3, strides=2))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(192, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, 3, strides=1,kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(3, strides=(1,2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(n_classes, activation='linear'))\n",
        "    return model    \n",
        "    \n",
        "def create_mobile_cnn(n_feats=128, chunk_size=512, n_classes=80):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_feats, chunk_size, 1)))\n",
        "              \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(10, kernel_size=(1,1), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(3, kernel_size=(1,1), padding='same', activation='relu'))\n",
        "    \n",
        "    mobilenet = MobileNetV2(include_top=False)\n",
        "    mobilenet.layers.pop(0)\n",
        "    model.add(mobilenet)\n",
        "    \n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "    return model\n",
        "              \n",
        "def plot_metric(hist, metric='loss', ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "        \n",
        "    ax.plot(hist.history[metric])\n",
        "    ax.plot(hist.history[f'val_{metric}'])\n",
        "    ax.set_title(f'{metric.upper()} vs Epoch')\n",
        "    ax.set_ylabel(metric.upper())\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.legend(['train', 'validation'], loc='upper right')\n",
        "#     plt.show()\n",
        "    \n",
        "def lw_lrap(y_true, y_pred):\n",
        "    \"\"\" Compute label-weighted label-ranking average precision. \n",
        "    Source: https://github.com/qiuqiangkong/dcase2019_task2/blob/master/utils/lwlrap.py\"\"\"\n",
        "    \n",
        "    weights = K.sum(y_true, axis=1)\n",
        "    score = tf.py_function(lrap, [y_true, \n",
        "                                  y_pred, \n",
        "                                  weights],\n",
        "                           tf.float32)                               \n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ea40Aa532dug"
      },
      "source": [
        "# Try out mixup\n",
        "hop_len = 512\n",
        "chunk_len = 4\n",
        "chunk_size = sr * chunk_len\n",
        "\n",
        "id1, sample1 = load_random_wav(train_curated_ids, train_curated_h5)\n",
        "label1 = get_label(id1, train_curated_labels)\n",
        "print(f'Initial label: {label1[label1>0]}')\n",
        "sample1 = random_chunk(sample1, chunk_size, hop_len)\n",
        "\n",
        "mixup_sample, mixup_label = mixup(sample1, label1, train_curated_ids, train_curated_h5, train_curated_labels, chunk_size, hop_len, alpha=1)\n",
        "print(f'Mixup label: {mixup_label[mixup_label>0]}')\n",
        "\n",
        "listen_sample(sample1)\n",
        "listen_sample(mixup_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KJsce6NE2duh"
      },
      "source": [
        "# Try out random gain\n",
        "id1, sample1 = load_random_wav(train_curated_ids, train_curated_h5)\n",
        "listen_sample(sample1)\n",
        "\n",
        "ampli_sample = random_ampli(sample1)\n",
        "listen_sample(ampli_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "NIz_Cow-2duh"
      },
      "source": [
        "# Feature extraction hyperparameters\n",
        "sr = 44100\n",
        "chunk_size = sr\n",
        "n_feats = 128\n",
        "hop = 512\n",
        "\n",
        "# Training hyperparameters\n",
        "batch_size = 32\n",
        "\n",
        "# Training/validation splits\n",
        "SEED = 42\n",
        "kf = list(ShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED).split(np.arange(len(train_curated_ids))))\n",
        "# kf = list(KFold(n_splits=5, shuffle=True, random_state=SEED).split(np.arange(len(train_mix_mel_paths))))\n",
        "\n",
        "models = {}\n",
        "hists = {}\n",
        "for fold_idx, (train_ids, valid_ids) in enumerate(kf):\n",
        "    print(f'Fold {fold_idx + 1} - {len(train_ids)} train ids / {len(valid_ids)} valid ids')\n",
        "    \n",
        "    # Define data loader\n",
        "    train_loader = DataLoader(train_curated_h5, train_curated_ids[train_ids], train_curated_labels.iloc[train_ids], batch_size, chunk_size, n_feats, hop, sr)\n",
        "    valid_loader = DataLoader(train_curated_h5, train_curated_ids[valid_ids], train_curated_labels.iloc[valid_ids], batch_size, chunk_size, n_feats, hop, sr)\n",
        "\n",
        "    # Define architecture\n",
        "    model = CNN9(n_feats, chunk_size, hop_len, n_classes).create_model()\n",
        "\n",
        "    # Train model\n",
        "    es = EarlyStopping(monitor='val_acc', mode='max', patience=5)\n",
        "    mc = ModelCheckpoint(f'best_model_{fold_idx}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc']) # lw_lrap\n",
        "\n",
        "    hist = model.fit(train_loader, steps_per_epoch=len(train_loader),\n",
        "                     validation_data=valid_loader,\n",
        "                     validation_steps=len(valid_loader),\n",
        "                     epochs=50, verbose=1, callbacks=[es, mc])\n",
        "    \n",
        "    # Save history and trained model\n",
        "    models[f'fold_{fold_idx}'] = model\n",
        "    hists[f'fold_{fold_idx}'] = hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zvuu1jcB2duh"
      },
      "source": [
        "fig, ax = plt.subplots(len(kf) +1 , 2, figsize=(15 ,3*len(kf)))\n",
        "\n",
        "for fold_idx in range(len(kf)):\n",
        "    plot_metric(hists[f'fold_{fold_idx}'], 'loss', ax=ax[fold_idx, 0])\n",
        "    plot_metric(hists[f'fold_{fold_idx}'], 'acc', ax=ax[fold_idx, 1])\n",
        "    fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHoleWa32dui"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ihglj5082dui"
      },
      "source": [
        "def load_random_test(paths_list):\n",
        "    path = np.random.choice(paths_list, 1)[0]\n",
        "    mel = np.load(path)\n",
        "    return mel\n",
        "\n",
        "def prepare_mel(mel, chunk_size=256, sr=44100):\n",
        "    n_mels, n_frames = mel.shape\n",
        "    \n",
        "    if n_frames <= chunk_size:\n",
        "        x = np.tile(mel, chunk_size//n_frames + 1)\n",
        "        x = x[np.newaxis, :, :chunk_size]\n",
        "    else:\n",
        "        n_crops = n_frames // chunk_size + 1\n",
        "        x = np.pad(mel, ([0,0], [0, n_crops * chunk_size - n_frames]))\n",
        "        x = np.split(x, n_crops, axis=-1)\n",
        "        x = np.array(x)\n",
        "        \n",
        "    features = normalize(x)\n",
        "    features = np.expand_dims(features, axis=-1)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def show_pred(models, mel, labels_list, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10,4))\n",
        "    \n",
        "    if not isinstance(models, list):\n",
        "        models = [models]\n",
        "    \n",
        "    mel = prepare_mel(mel)\n",
        "    pred = average_models_pred(models, mel)\n",
        "    \n",
        "    top5_idx = np.argsort(pred)[::-1][:5]\n",
        "    top_labels = labels_list[top5_idx]\n",
        "    top_preds = pred[top5_idx]\n",
        "    \n",
        "    ax.bar(top_labels, top_preds)\n",
        "    \n",
        "def average_models_pred(models, mel):\n",
        "    preds = [ np.mean(m.predict(mel), axis=0) for m in models ]\n",
        "    return np.mean(preds, axis=0)\n",
        "    \n",
        "def create_submission(models, save_name='model_preds'):\n",
        "    submission_df = pd.read_csv('/kaggle/input/freesound-audio-tagging-2019/sample_submission.csv', index_col='fname')\n",
        "    test_mel_paths = glob.glob('/kaggle/input/logmel128/test_logmel/*.npy')\n",
        "    \n",
        "    for path in test_mel_paths:\n",
        "        mel = np.load(path)\n",
        "        mel = prepare_sample(mel)\n",
        "        pred = average_models_pred(models, mel)        \n",
        "        submission_df.loc[path.split('/')[-1]] = pred\n",
        "    \n",
        "    submission_df.to_csv(f'{save_name}.csv',index = False)\n",
        "    print(f'Successfully created {save_name}.csv !')\n",
        "    \n",
        "    return submission_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aP1NVJPq2duj"
      },
      "source": [
        "mel_test = load_random_test(test_mel_paths)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 3))\n",
        "\n",
        "trained_models = list(models.values())\n",
        "# trained_models = [ m.load_weights(f'best_model_{i}.h5') for i,m in enumerate(trained_models) ]\n",
        "\n",
        "show_pred(trained_models, mel_test, train_curated_labels.columns, ax=ax)    \n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "reBo-dFn2duj"
      },
      "source": [
        "audio = convert_spectra2sound(mel_test)\n",
        "listen_sample(audio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jxkwdReZ2duk"
      },
      "source": [
        "sub = create_submission(model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpvBY9z2duk"
      },
      "source": [
        "# TODO\n",
        "\n",
        "**Debugging:**\n",
        "- [x] Try out on a reduced dataset (~10 labels) -> add a flag to load reduced dataset.\n",
        "\n",
        "**Preprocessing:**\n",
        "- [ ] Trim silences\n",
        "- [ ] Augmentation pipeline (random shift, pitch, noise, ...) [Mixup paper](https://arxiv.org/pdf/1710.09412.pdf)\n",
        "- [x] Improving feature extraction (import as separate dataset)\n",
        "- [ ] Write signal transformers (wrap padding, centering, trimming)\n",
        "\n",
        "**Modelling:**\n",
        "- [ ] Reproduce baseline [github](https://github.com/qiuqiangkong/dcase2019_task2)\n",
        "- [ ] Implement approach from [this paper](http://dcase.community/documents/challenge2019/technical_reports/DCASE2019_Akiyama_94_t2.pdf).\n",
        "- [ ] Take a look at [this notebook](https://www.kaggle.com/romul0212/freesound-predict-dataset) and associated [github](https://github.com/lRomul/argus-freesound)\n",
        "- [ ] Try out the approach described in [this paper](https://arxiv.org/pdf/1904.03476.pdf).\n",
        "- [ ] Explore ensemble learning strategy [from this paper](https://arxiv.org/pdf/1810.12832.pdf) and associated [github](https://github.com/Cocoxili/DCASE2018Task2/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IAIybpmA2duk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}